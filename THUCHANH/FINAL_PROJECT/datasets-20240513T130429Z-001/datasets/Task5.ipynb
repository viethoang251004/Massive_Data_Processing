{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAfBqyDXWTqG",
        "outputId": "c58a73a9-a93e-4796-aec3-5070d442dfd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\python312\\lib\\site-packages (3.5.1)\n",
            "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.8.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.21 in c:\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-Z2EO_dT8g1U",
        "outputId": "216eeed7-6898-483b-d68e-24f6f458478f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVcElEQVR4nO3deVxN+f8H8Ndtu7fd0k6K7COppMm+REj2fauQMTSW7AaJGRkzkd0wlDGhsRvrEI2xjOxrQiSi0hiVLOV2fn/4db/uVHSTbp15PR+P++B+zuec8z6nU70653POlQiCIICIiIhIJDTUXQARERFRSWK4ISIiIlFhuCEiIiJRYbghIiIiUWG4ISIiIlFhuCEiIiJRYbghIiIiUWG4ISIiIlFhuCEiIiJRYbghKuckEgnmzJmj7jI+2saNG1G3bl1oa2ujQoUK6i4nn4SEBEgkEoSHh6s8b3R0NCQSCaKjo0u8LjEKDw+HRCJBQkKCukuhcorhhsq9+Ph4fPHFF6hRowZkMhmMjIzQrFkzLFmyBC9fvlR3eVQEN2/ehI+PD+zs7LB27VqsWbOm0L5z5syBRCKBhoYGHjx4kG96RkYGdHV1IZFI4O/v/ynL/qRWrlwJiUQCV1dXdZdCVO5oqbsAoo+xb98+9OnTB1KpFEOHDkWDBg2QnZ2NEydOYPLkybh+/fp7f1GKwcuXL6GlVb6/laOjo5Gbm4slS5agZs2aRZpHKpVi8+bNmDJlilL7jh07PkWJpS4iIgK2traIiYnBnTt3irxfxGDIkCHo378/pFKpukuhcopnbqjcunfvHvr37w8bGxvcuHEDS5YsgZ+fH8aMGYPNmzfjxo0b+Oyzz9Rd5ieRm5uLV69eAQBkMlm5DzepqakAoNLlqM6dO2Pz5s352jdt2gRPT8+SKk0t7t27h1OnTmHRokUwNTVFRESEuksqVFZWVokvU1NTEzKZDBKJpMSXTf8NDDdUbi1cuBDPnz/HunXrYGlpmW96zZo1MW7cOMX7N2/eYN68ebCzs4NUKoWtrS1mzJiB169fK81na2uLLl26IDo6Go0bN4auri7s7e0V4yV27NgBe3t7yGQyODs74+LFi0rz+/j4wMDAAHfv3oWHhwf09fVhZWWFuXPnQhAEpb4//PADmjZtisqVK0NXVxfOzs7Ytm1bvm3Ju8QSERGBzz77DFKpFAcPHlRMe3fMTWZmJsaPHw9bW1tIpVKYmZmhffv2uHDhgtIyt27dCmdnZ+jq6sLExASDBw9GUlJSgduSlJSE7t27w8DAAKamppg0aRLkcnkhXxllK1euVNRsZWWFMWPG4NmzZ0r7OzAwEABgampa5DFEAwcOxKVLl3Dz5k1FW3JyMo4ePYqBAwcWOE9qaiqGDx8Oc3NzyGQyODg4YMOGDfn6PXv2DD4+PjA2NkaFChXg7e2tVPO7bt68id69e6NSpUqQyWRo3Lgx9uzZ88H63yciIgIVK1aEp6cnevfuXWi4efbsGSZMmKD4WletWhVDhw5FWlqaos+rV68wZ84c1K5dGzKZDJaWlujZsyfi4+MBFD4eqKAxRnnHQ3x8PDp37gxDQ0MMGjQIAPDnn3+iT58+qFatGqRSKaytrTFhwoQCLw3fvHkTffv2hampKXR1dVGnTh18/fXXiumFjbk5cOAAWrRoAX19fRgaGsLT0xPXr19X6pOcnAxfX19UrVoVUqkUlpaW6NatG8fv/Mcw3FC59dtvv6FGjRpo2rRpkfqPGDECs2fPhpOTExYvXoxWrVohODgY/fv3z9f3zp07GDhwILy8vBAcHIx//vkHXl5eiIiIwIQJEzB48GAEBQUhPj4effv2RW5urtL8crkcHTt2hLm5ORYuXAhnZ2cEBgYqfonnWbJkCRwdHTF37lzMnz8fWlpa6NOnD/bt25evpqNHj2LChAno168flixZAltb2wK3c9SoUVi1ahV69eqFlStXYtKkSdDV1UVsbKyiT3h4OPr27QtNTU0EBwfDz88PO3bsQPPmzfP9EpfL5fDw8EDlypXxww8/oFWrVggJCSnS5b45c+ZgzJgxsLKyQkhICHr16oUff/wRHTp0QE5ODgAgNDQUPXr0AACsWrUKGzduRM+ePT+47JYtW6Jq1arYtGmToi0yMhIGBgYFnrl5+fIlWrdujY0bN2LQoEH4/vvvYWxsDB8fHyxZskTRTxAEdOvWDRs3bsTgwYPxzTff4OHDh/D29s63zOvXr+Pzzz9HbGwspk2bhpCQEOjr66N79+7YuXPnB7ehMBEREejZsyd0dHQwYMAA3L59G2fPnlXq8/z5c7Ro0QLLli1Dhw4dsGTJEowaNQo3b97Ew4cPAbz92nXp0gVBQUFwdnZGSEgIxo0bh/T0dFy7dq1Ytb158wYeHh4wMzPDDz/8gF69egF4G5ZfvHiBL7/8EsuWLYOHhweWLVuGoUOHKs1/5coVuLq64ujRo/Dz88OSJUvQvXt3/Pbbb+9d78aNG+Hp6QkDAwN89913mDVrFm7cuIHmzZsrBZdevXph586d8PX1xcqVKzF27FhkZmYiMTGxWNtL5ZRAVA6lp6cLAIRu3boVqf+lS5cEAMKIESOU2idNmiQAEI4ePapos7GxEQAIp06dUrQdOnRIACDo6uoK9+/fV7T/+OOPAgDh2LFjijZvb28BgPDVV18p2nJzcwVPT09BR0dHePLkiaL9xYsXSvVkZ2cLDRo0ENq2bavUDkDQ0NAQrl+/nm/bAAiBgYGK98bGxsKYMWMK3RfZ2dmCmZmZ0KBBA+Hly5eK9r179woAhNmzZ+fblrlz5yotw9HRUXB2di50HYIgCKmpqYKOjo7QoUMHQS6XK9qXL18uABDWr1+vaAsMDBQAKO2bwrzbd9KkSULNmjUV01xcXARfX19BEN7ul3f3Q2hoqABA+OWXX5T2hZubm2BgYCBkZGQIgiAIu3btEgAICxcuVPR78+aN0KJFCwGAEBYWpmhv166dYG9vL7x69UrRlpubKzRt2lSoVauWou3YsWP5jpPCnDt3TgAgHD58WLG8qlWrCuPGjVPqN3v2bAGAsGPHjnzLyM3NFQRBENavXy8AEBYtWlRon8Jqu3fvXr7tzTsepk2blm95/z6WBUEQgoODBYlEovQ907JlS8HQ0FCp7d16BEEQwsLCBADCvXv3BEEQhMzMTKFChQqCn5+f0jzJycmCsbGxov2ff/4RAAjff/99vlrov4VnbqhcysjIAAAYGhoWqf/+/fsBAAEBAUrtEydOBIB8Z0rq168PNzc3xfu8O1batm2LatWq5Wu/e/duvnW+e6dO3mWl7OxsHDlyRNGuq6ur+P8///yD9PR0tGjRIt8lJABo1aoV6tev/4EtfTtu5cyZM3j06FGB08+dO4fU1FSMHj0aMplM0e7p6Ym6desWeNZo1KhRSu9btGhR4Da/68iRI8jOzsb48eOhofG/HzV+fn4wMjIqcD2qGjhwIO7cuYOzZ88q/i3sktT+/fthYWGBAQMGKNq0tbUxduxYPH/+HH/88Yein5aWFr788ktFP01NTXz11VdKy3v69CmOHj2Kvn37IjMzE2lpaUhLS8Pff/8NDw8P3L59O99lvqKIiIiAubk52rRpA+DtsdOvXz9s2bJF6VLg9u3b4eDgoDjr9a68sSrbt2+HiYlJvtrf7VMc7+6bPO8ey1lZWUhLS0PTpk0hCILi0u2TJ09w/PhxDBs2TOn76EP1HD58GM+ePcOAAQMU+zktLQ2amppwdXXFsWPHFDXo6OggOjoa//zzT7G3j8o/hhsql4yMjAC8HV9SFPfv34eGhka+O04sLCxQoUIF3L9/X6n93z94jY2NAQDW1tYFtv/7B6mGhgZq1Kih1Fa7dm0AUDqFvnfvXnz++eeQyWSoVKkSTE1NsWrVKqSnp+fbhurVq39oMwG8HYt07do1WFtbo0mTJpgzZ45SEMnb1jp16uSbt27duvn2hUwmg6mpqVJbxYoVP/jLo7D16OjooEaNGvnWUxyOjo6oW7cuNm3ahIiICFhYWKBt27aF1lOrVi2loAUA9erVU6r3/v37sLS0hIGBgVK/f2/HnTt3IAgCZs2aBVNTU6VX3uXHvIHSRSWXy7Flyxa0adMG9+7dw507d3Dnzh24uroiJSUFUVFRir7x8fFo0KDBe5cXHx+POnXqlOiAcy0tLVStWjVfe2JiInx8fFCpUiXF2KxWrVoBgOJ4zjsOP1T3v92+fRvA2z8u/r2vf//9d8V+lkql+O6773DgwAGYm5ujZcuWWLhwIZKTk4u9vVQ+le9bLOg/y8jICFZWViqPGyjqX6uampoqtQv/GihcFH/++Se6du2Kli1bYuXKlbC0tIS2tjbCwsKUxpHkefcv4/fp27cvWrRogZ07d+L333/H999/j++++w47duxAp06dVK6zsG0uKwYOHIhVq1bB0NAQ/fr1yxdePpW8cVaTJk2Ch4dHgX1UvX376NGjePz4MbZs2YItW7bkmx4REYEOHTqoXux7FPY9UdiAcalUmm8fy+VytG/fHk+fPsXUqVNRt25d6OvrIykpCT4+PvnGpKkqb/6NGzfCwsIi3/R3w9v48ePh5eWFXbt24dChQ5g1axaCg4Nx9OhRODo6flQdVH4w3FC51aVLF6xZswanT59WuoRUEBsbG+Tm5uL27duKv9QBICUlBc+ePYONjU2J1pabm4u7d+8qztYAwK1btwBAMRB4+/btkMlkOHTokNLzPMLCwj56/ZaWlhg9ejRGjx6N1NRUODk54dtvv0WnTp0U2xoXF5fvLEdcXFyJ7Yt31/PuWazs7Gzcu3cP7u7uJbKegQMHYvbs2Xj8+DE2btz43nquXLmC3NxcpV/OeXdb5dVrY2ODqKgoPH/+XOnsTVxcnNLy8rZJW1u7xLYlIiICZmZmWLFiRb5pO3bswM6dO7F69Wro6urCzs7ug+Hezs4OZ86cQU5ODrS1tQvsU7FiRQDIN5BclTNrV69exa1bt7BhwwalAcSHDx9W6pe3z1T9o8TOzg4AYGZmVqR9bWdnh4kTJ2LixIm4ffs2GjVqhJCQEPzyyy8qrZfKL16WonJrypQp0NfXx4gRI5CSkpJvenx8vOIumM6dOwN4e2fOuxYtWgQAn+S5KMuXL1f8XxAELF++HNra2mjXrh2At2dEJBKJ0l/ICQkJ2LVrV7HXKZfL813SMjMzg5WVleKW98aNG8PMzAyrV69Wug3+wIEDiI2NLbF94e7uDh0dHSxdulTpzNa6deuQnp5eYuuxs7NDaGgogoOD0aRJk0L7de7cGcnJyYiMjFS0vXnzBsuWLYOBgYHiEkrnzp3x5s0brFq1StFPLpdj2bJlSsszMzND69at8eOPP+Lx48f51vfkyROVtuPly5fYsWMHunTpgt69e+d7+fv7IzMzU3Gbea9evXD58uUC78rK29+9evVCWlqa0rH47z42NjbQ1NTE8ePHlaavXLmyyLXnnd179+ssCILSXWjA21v9W7ZsifXr1+e7e+l9Zz89PDxgZGSE+fPnK+6ye1fevn7x4oXi+U957OzsYGhomO+RDyRuPHND5ZadnR02bdqEfv36oV69ekpPKD516hS2bt0KHx8fAICDgwO8vb2xZs0aPHv2DK1atUJMTAw2bNiA7t27KwZvlhSZTIaDBw/C29sbrq6uOHDgAPbt24cZM2Yoxq94enpi0aJF6NixIwYOHIjU1FSsWLECNWvWxJUrV4q13szMTFStWhW9e/eGg4MDDAwMcOTIEZw9exYhISEA3p5p+O677+Dr64tWrVphwIABSElJUdxePmHChBLZB6amppg+fTqCgoLQsWNHdO3aFXFxcVi5ciVcXFwwePDgElkPAKXnGRVm5MiR+PHHH+Hj44Pz58/D1tYW27Ztw8mTJxEaGqoYnO7l5YVmzZph2rRpSEhIQP369bFjx44Cx0GtWLECzZs3h729Pfz8/FCjRg2kpKTg9OnTePjwIS5fvlzkbdizZw8yMzPRtWvXAqd//vnnigf69evXD5MnT8a2bdvQp08fDBs2DM7Oznj69Cn27NmD1atXw8HBAUOHDsXPP/+MgIAAxMTEoEWLFsjKysKRI0cwevRodOvWDcbGxujTpw+WLVsGiUQCOzs77N27V6XxQnXr1oWdnR0mTZqEpKQkGBkZYfv27QWOy1q6dCmaN28OJycnjBw5EtWrV0dCQgL27duHS5cuFbh8IyMjrFq1CkOGDIGTkxP69+8PU1NTJCYmYt++fWjWrBmWL1+OW7duoV27dujbty/q168PLS0t7Ny5EykpKQU+8oFETF23aRGVlFu3bgl+fn6Cra2toKOjIxgaGgrNmjUTli1bpnSLbk5OjhAUFCRUr15d0NbWFqytrYXp06cr9RGEt7eCe3p65lsP/nVrsSD873bZd2899fb2FvT19YX4+HihQ4cOgp6enmBubi4EBgYq3RItCIKwbt06oVatWoJUKhXq1q0rhIWFKW51/tC6352Wdyv469evhcmTJwsODg6CoaGhoK+vLzg4OAgrV67MN19kZKTg6OgoSKVSoVKlSsKgQYOEhw8fKvXJ25Z/K6jGwixfvlyoW7euoK2tLZibmwtffvml8M8//xS4PFVvBX+fgvZZSkqK4OvrK5iYmAg6OjqCvb290q3Oef7++29hyJAhgpGRkWBsbCwMGTJEuHjxYr5bowVBEOLj44WhQ4cKFhYWgra2tlClShWhS5cuwrZt2xR9inIruJeXlyCTyYSsrKxC+/j4+Aja2tpCWlqaok5/f3+hSpUqgo6OjlC1alXB29tbMV0Q3t6i/fXXXyuOewsLC6F3795CfHy8os+TJ0+EXr16CXp6ekLFihWFL774Qrh27VqBt4IXdDwIgiDcuHFDcHd3FwwMDAQTExPBz89PuHz5coH77Nq1a0KPHj2EChUqCDKZTKhTp44wa9YsxfR/3wr+7n708PAQjI2NBZlMJtjZ2Qk+Pj7CuXPnBEEQhLS0NGHMmDFC3bp1BX19fcHY2FhwdXUVfv3110L3KYmTRBCKMRKSiArl4+ODbdu24fnz5+ouhYjoP4ljboiIiEhUGG6IiIhIVBhuiIiISFQ45oaIiIhEhWduiIiISFQYboiIiEhU/nMP8cvNzcWjR49gaGj4UZ+KS0RERKVHEARkZmbCysrqg58h958LN48ePcr3yc5ERERUPjx48KDAT6Z/138u3OQ9Yv3BgwcwMjJSczVERERUFBkZGbC2tlb8Hn+f/1y4ybsUZWRkxHBDRERUzhRlSAkHFBMREZGoMNwQERGRqDDcEBERkaj858bcEBFRyZHL5cjJyVF3GSQSOjo6H7zNuygYboiISGWCICA5ORnPnj1TdykkIhoaGqhevTp0dHQ+ajkMN0REpLK8YGNmZgY9PT0+FJU+Wt5Ddh8/foxq1ap91DHFcENERCqRy+WKYFO5cmV1l0MiYmpqikePHuHNmzfQ1tYu9nI4oJiIiFSSN8ZGT09PzZWQ2ORdjpLL5R+1HIYbIiIqFl6KopJWUscUww0RERGJilrDzfHjx+Hl5QUrKytIJBLs2rXrg/NER0fDyckJUqkUNWvWRHh4+Cevk4iIqCC2trYIDQ1Vdxn0L2odUJyVlQUHBwcMGzYMPXv2/GD/e/fuwdPTE6NGjUJERASioqIwYsQIWFpawsPDoxQqJiKi97Gdtq/U1pWwwLPIfT90uSMwMBBz5sxRuYazZ89CX19f5fkKsnnzZgwePBijRo3CihUrSmSZ/1VqDTedOnVCp06ditx/9erVqF69OkJCQgAA9erVw4kTJ7B48WKGGyIiKtTjx48V/4+MjMTs2bMRFxenaDMwMFD8XxAEyOVyaGl9+FekqalpidW4bt06TJkyBT/++CNCQkIgk8lKbNmqys7O/uhnzahTuRpzc/r0abi7uyu1eXh44PTp02qqiIiIygMLCwvFy9jYGBKJRPH+5s2bMDQ0xIEDB+Ds7AypVIoTJ04gPj4e3bp1g7m5OQwMDODi4oIjR44oLfffl6UkEgl++ukn9OjRA3p6eqhVqxb27Nnzwfru3buHU6dOYdq0aahduzZ27NiRr8/69evx2WefQSqVwtLSEv7+/oppz549wxdffAFzc3PIZDI0aNAAe/fuBQDMmTMHjRo1UlpWaGgobG1tFe99fHzQvXt3fPvtt7CyskKdOnUAABs3bkTjxo1haGgICwsLDBw4EKmpqUrLun79Orp06QIjIyMYGhqiRYsWiI+Px/Hjx6GtrY3k5GSl/uPHj0eLFi0+uE8+RrkKN8nJyTA3N1dqMzc3R0ZGBl6+fFngPK9fv0ZGRobSi4iI6N+mTZuGBQsWIDY2Fg0bNsTz58/RuXNnREVF4eLFi+jYsSO8vLyQmJj43uUEBQWhb9++uHLlCjp37oxBgwbh6dOn750nLCwMnp6eMDY2xuDBg7Fu3Tql6atWrcKYMWMwcuRIXL16FXv27EHNmjUBvH34XadOnXDy5En88ssvuHHjBhYsWABNTU2Vtj8qKgpxcXE4fPiwIhjl5ORg3rx5uHz5Mnbt2oWEhAT4+Pgo5klKSkLLli0hlUpx9OhRnD9/HsOGDcObN2/QsmVL1KhRAxs3blT0z8nJQUREBIYNG6ZSbaoS/UP8goODERQUVGrrK83rzR+SIBuo7hLKnjnp6q6gzOExW8bxmC3UlYfPijXfg6cvkCsIivnjnzwHAAwbOxXm9VyQBSDrBSCpbAM3TxvkAngJoM8XE7H5121Y9fMWDPAZ+XZh8mwg/SHw6KJi+T69OmJAq7oAMjH/q35YunQpYg5sQsc2zQqsJzc3F+Hr1mLZN1OARxfRv3V9TJwYgHt/7UX1alUAAN/MDcTEkYMwrk9LAFmAgRZc+rYCHl3EkT9OIyYmBrHR21HbzgRAOmo4vZ0Pjy4CmY+BnJdKNSL94dva89pePIW+rhQ/zfWHjk62Yt5hHR3zZkCNalIsnTUGLp0H4/ntkzDQ18OKBctgbKCLLYumQltbE0AWans0AqzenvkZPnw4wsLCMHnyZADAb7/9hlevXqFv377F+MoVXbk6c2NhYYGUlBSltpSUFBgZGUFXV7fAeaZPn4709HTF68GDB6VRKhERlTP1GzZSev8i6zlC5s1C9zauaP6ZDT6vUxX37txCctLD9y6nYb1aiv/r6+nCyNAAqWn/FNr/8PG/kPXiJTq3fRt+TCpVRPsWrli/ZTcAIDXtKR4lP0G75k0KnP/S9ThUtTRDbTubomxmoezr1oSOjvJTgc9fuQEv73Go5tIZhrWbo1WvEQCAxKS3l5ou3biFFk0cC32asI+PD+7cuYO//voLABAeHo6+ffuW2CDswpSrMzdubm7Yv3+/Utvhw4fh5uZW6DxSqRRSqfRTl0ZEROWcrp7yL9yQb2bhr+PRCJg5D9Vsq0Mq08WkUd4f/BR0bW3lX60SyduzM4VZt3k3nj5Lh65dU0Vbbm4ursTeQdCkUdCVvf93mO4HBh5raGhAEASltpw3b/L109dTPkmQ9eIlPAb6w6O1GyKWfwPTyhWRmJQMj4FjkJ2d8//rfn9tZmZm8PLyQlhYGKpXr44DBw4gOjr6vfOUBLWGm+fPn+POnTuK9/fu3cOlS5dQqVIlVKtWDdOnT0dSUhJ+/vlnAMCoUaOwfPlyTJkyBcOGDcPRo0fx66+/Yt++snNanYiIxOHS2TPo2mcg2nXqAuDtmZxHD98/3kZVfz99ht2/R2PLymB8VsdO0S6X56J5j2H4/Y/T6NimGWytrRB1IgZtmrnkW0bDerXw8HEqbsXfL/DsjWmlikh+8jcEQVDcEn/p+q0P1nbzzj38/c8zLJj+FayrWAAAzl2+kW/dG7buRU5OTqFnb0aMGIEBAwagatWqsLOzQ7NmBV+eK0lqvSx17tw5ODo6wtHx7TW9gIAAODo6Yvbs2QDe3rr37sCt6tWrY9++fTh8+DAcHBwQEhKCn376ibeBExFRiatW3Q5RB3/DzetXEXfjKqb5+yE3V/jwjCrYuH0fKlc0Rt+uHdCgbk3Fy+Gz2ujcthnWbX57aWpOwBcIWfMLlq7bjNt3E3HhaiyWrd8CAGjl5oyWrk7oNXIyDh//C/cSk3Dg6EkcPHYSANC6qTOe/P0PFq7cgPiEB1gRHokD/z/tvdtfxRI6OtpYFrYFd+8/xJ7f/8C80J+U+vj79ENGZhb6j56Oc5dv4PbdRGzctlfpNnsPDw8YGRnhm2++ga+vb0ntuvdSa7hp3bo1BEHI98p76nB4eHi+01etW7fGxYsX8fr1a8THxyuN2iYiIiopk2Z/CyPjCvDu7oGxvgPQtFVb1GvQsETXsT5yN3p0bFPgQwZ7dW6HPYf/QNrTf+Dd1wuhcyZi5Yat+Kxtb3TxHofb9/73x//2td/DxaE+BoyegfptemPKt0sgl7+9FFavVg2snD8dK8J/hUP7/oi5eB2TvhjywdpMK1dE+OIgbN17BPXb9MaC5WH4YdZ4pT6VK1XA0V9X43nWC7TqNQLOnQZh7aadSmdxNDQ04OPjA7lcjqFDhxZzT6lGIvz7QpzIZWRkwNjYGOnp6TAyMirx5fPOkzKOd57kw2O2jCuDx+yrV69w7949VK9eXW0PmivunVIlraHGPXWXUDZZOSq9HT58OJ48efLBZ/6879hS5fd3uRpQTEREROVHeno6rl69ik2bNhXpYYYlheGGiIiIPolu3bohJiYGo0aNQvv27UttvQw3RERE9EmUxm3fBSlXD/EjIiIi+hCGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhU+54aIiErOHONSWU1DAFdG3C9yfwfriu+dPmrCVHwZMK1YtUiqOGHnuhB079imSP2/mPINftq8C1tWBqOPV+k92O6/hOGGiIhEL+r8TcX/D/22EytD5mN39FlFm56+fqnU8eLlS2zZ8zumjPbG+sjdag832dk50NHR/nDHcoaXpYiISPRMzMwVLwNDI0gkEqW2g3t2oHsbV7jUtEC31k0QueEnxbw52dmYP3My2jnXhUtNC3T83B7rli8CANi6egIAegyfCEkVJ8X7wmz97Qjq16qOaWN8cPyvC3iQlKw0/fXrbEz9dgmsG3eCtLorajbrinWbdymmX4+LR5ehY2FUpwUMazdHix7DEJ/wAADQurcfxs/+Xml53YcFwGd8oOK9rasn5i1ei6FjZ8GoTguMnPINAGDqt0tQu3l36Nk1RQ03L8xauBI5OTlKy/rt9z/g0nkwZDU+h0mDtugxfCIAYO7iNWjQtk++bW3UqBFmzZr13v3xqfDMDRER/aft2/krVv4QjGnfLETdzxri5vUrmDtlHHT19NG1zwBsWv8j/jh8AN+vXA+LKlWR/CgJKY+SAABn9/8Cs4btELZoDjq2aQpNTc33rmvdll0Y3KszjI0M0alNM4T/+htmTfBTTB86bhZOn7+KpfMmw6F+bdxLTELa02cAgKTHqWjZcwRaN3XG0V9/hJGBPk6eu4Q3b+Qqbe8PP27E7PF+CAwYqWgz1NdH+OIgWFmY4mrsbfhN+QaGBnqYMtrn7T468id6jJiEr8cOw89L5iI7+w32Hz0BABjWrxuCFq3B2UvX4dLoMwDAxYsXceXKFezYsUOl2koKww0REf2nrQpZgImz5sG9kxcAoGo1G9y9FYdtEWHo2mcAHj96iGrV7eDYxA0SiQRWVasp5jWt/HYsTwVjQ1iYmbx3PbfvJuKvC1ex46cfAACDe3VGQNAizBw/AhKJBLfi7+PX3w7j8OZVcG/pCgCoYVNVMf+K8EgYGxlgy8pgaGu/vZRU285G5e1t28wFE0cNUWqbOX6E4v+21laYdPc+tuw+pAg33y5dh/7dOiBo0peKfg6f1QYAVLUyh0drN4RF7lGEm7CwMLRq1Qo1atRQub6SwMtSRET0n/XiRRYe3L+HOZPH4vM6VRWvtct+wIP7CQCAbn0GIu76VXRt5YIFs6fi1B9Hi7Wu9ZG74dHKDSaV3gaizm2bIz3jOY6eiAEAXLoeB01NTbRycypw/ks3bqFFE0dFsCmuxg3r5WuL3H0Izbr5wqJRexjUaoaZC1ci8Z1LZpeu30K75k0KXabfwB7YvPsgXr16jezsHGzatAnDhg37qDo/Bs/cEBHRf9bLrCwAwOyFobBv1Fhpmsb/X2KqZ++A/acu4cSxIzhz4g9MGe0L1+atEfLjhiKvRy6XY8PW35Cc+je0qrkota+P3IN2LVyhK5O+dxkfmq4hkUD4V1tOzpt8/fT1dJXenz53GYO+momgiV/Ao3VTGBsaYMvuQwhZs7HI6/Zq3xJSHR3sPHgMOtrayMnJQe/evd87z6fEcENERP9ZlU3NYGpuiYf378OzR99C+xkYGqFj157o2LUn3Dt3xeghvZH+zz9AZUBbWwtyee5717M/6gQyn7/AxUOboan5v4sm1+Li4RswB8/SM2FfrxZyc3Pxx+kListS72pYrxY2bN2LnJycAs/emFauiMcpaYr3crkc1+LuoE1Tl3x933Xq3BXYVLXE1+P+d2nqftLjfOuOOhED337dClyGlpYWvPt0QVjkHuhoa6F///7Q1dUtsG9p4GUpIiL6Txs9cRrWr1iMiPU/IuHuHdyOvY5dkRH4ec0KAMDPa1bgwK5tuHfnFhLu3sHhfbthYmYOQ+O3z/SxrWqFqBMxSE5Nwz/PMgpcx7otu+HZrjkcPquNBnVrKl59vdqjgpEhInbuh621Fbz7dMGwiUHYdfAY7iUmIfrUOfy653cAgL9PP2RkZqH/6Ok4d/kGbt9NxMZtexF3JwHA27E0+6L+xL4jf+LmnXv4cvp8PMt4/sHtr1WjGhKTkrFl9yHEJzzA0nWbsfPAMaU+gQEjsXnXIQT+sAqxt+/iauxtfLciXKnPiAE9cPTkWRyMPq3WS1IAww0REf3H9RwwFIELl2D3rxHo3b4ZhvXpgj1bN6GK9dvBuvoGBghbvRQDPNtiUJe2ePQwEcs3/AoNjbe/QkNmT8Dh43/B2qUzHD0G5Ft+ypO/sS/qBHp1bpdvmoaGBnp0bIN1m3cDAFYFz0Bvz3YYPSMYdVv1hN/kech6+RIAULlSBRz9dTWeZ71Aq14j4NxpENZu2glt7bcXYYb17wbvPl4YOm42WvXyQ41qVdGmaeN86/y3rh1aYYLfQPh//R0adRiAU+cuY9Y7A4wBoHXTxtj643fY8/txNOowAG37foGYS9eU+tSqUQ1NGzdE3Zq2cHXNf+apNEkEQfj3JTpRy8jIgLGxMdLT02FkZFTiy7edtq/El1lcCbKB6i6h7JmTru4Kyhwes2VcGTxmX716hXv37qF69eqQyWRqqeHKw2dqWe+/NdS4p+4SygxBEFCreTeMHtoXAUEhxVrG+44tVX5/c8wNERERfZQnf/+DLbsPITn1b/j266ruchhuiIiI6OOYNWwHk0oVsGbhTFSsUPJXRVTFcENEREQfRUi6oO4SlHBAMREREYkKww0RERXLf+x+FCoFJXVMMdwQEZFK8h4g9+LFCzVXQmKTnZ0NAB/8ANIP4ZgbIiJSiaamJipUqIDU1FQAgJ6eHiQSSanWILzJLtX1FeaVBs9eFejVK5Vnyc3NxZMnT6CnpwctrY+LJww3RESkMgsLCwBQBJzSlvrPS7Ws9990JE/UXULZlFW85/9oaGigWrVqHx2WGW6IiEhlEokElpaWMDMzQ05OTqmvf8SO6FJfZ0GipJPUXULZ5H+uWLPp6Ogonvz8MRhuiIio2DQ1NT96fERxJGXKS32dBZHlPFB3CWWTmp5cnYcDiomIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhU1B5uVqxYAVtbW8hkMri6uiImJua9/UNDQ1GnTh3o6urC2toaEyZMwKtXr0qpWiIiIirr1BpuIiMjERAQgMDAQFy4cAEODg7w8PBAampqgf03bdqEadOmITAwELGxsVi3bh0iIyMxY8aMUq6ciIiIyiq1hptFixbBz88Pvr6+qF+/PlavXg09PT2sX7++wP6nTp1Cs2bNMHDgQNja2qJDhw4YMGDAB8/2EBER0X+H2sJNdnY2zp8/D3d39/8Vo6EBd3d3nD59usB5mjZtivPnzyvCzN27d7F//3507ty50PW8fv0aGRkZSi8iIiISLy11rTgtLQ1yuRzm5uZK7ebm5rh582aB8wwcOBBpaWlo3rw5BEHAmzdvMGrUqPdelgoODkZQUFCJ1k5ERERll9oHFKsiOjoa8+fPx8qVK3HhwgXs2LED+/btw7x58wqdZ/r06UhPT1e8Hjx4UIoVExERUWlT25kbExMTaGpqIiUlRak9JSUFFhYWBc4za9YsDBkyBCNGjAAA2NvbIysrCyNHjsTXX38NDY38WU0qlUIqlZb8BhAREVGZpLYzNzo6OnB2dkZUVJSiLTc3F1FRUXBzcytwnhcvXuQLMJqamgAAQRA+XbFERERUbqjtzA0ABAQEwNvbG40bN0aTJk0QGhqKrKws+Pr6AgCGDh2KKlWqIDg4GADg5eWFRYsWwdHREa6urrhz5w5mzZoFLy8vRcghIiKi/za1hpt+/frhyZMnmD17NpKTk9GoUSMcPHhQMcg4MTFR6UzNzJkzIZFIMHPmTCQlJcHU1BReXl749ttv1bUJREREVMaoNdwAgL+/P/z9/QucFh0drfReS0sLgYGBCAwMLIXKiIiIqDwqV3dLEREREX0Iww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJCsMNERERiQrDDREREYkKww0RERGJitrDzYoVK2BrawuZTAZXV1fExMS8t/+zZ88wZswYWFpaQiqVonbt2ti/f38pVUtERERlnZY6Vx4ZGYmAgACsXr0arq6uCA0NhYeHB+Li4mBmZpavf3Z2Ntq3bw8zMzNs27YNVapUwf3791GhQoXSL56IiIjKJJXP3Nja2mLu3LlITEz86JUvWrQIfn5+8PX1Rf369bF69Wro6elh/fr1BfZfv349nj59il27dqFZs2awtbVFq1at4ODg8NG1EBERkTioHG7Gjx+PHTt2oEaNGmjfvj22bNmC169fq7zi7OxsnD9/Hu7u7v8rRkMD7u7uOH36dIHz7NmzB25ubhgzZgzMzc3RoEEDzJ8/H3K5XOX1ExERkTgVK9xcunQJMTExqFevHr766itYWlrC398fFy5cKPJy0tLSIJfLYW5urtRubm6O5OTkAue5e/cutm3bBrlcjv3792PWrFkICQnBN998U+h6Xr9+jYyMDKUXERERiVexBxQ7OTlh6dKlePToEQIDA/HTTz/BxcUFjRo1wvr16yEIQknWCQDIzc2FmZkZ1qxZA2dnZ/Tr1w9ff/01Vq9eXeg8wcHBMDY2Vrysra1LvC4iIiIqO4odbnJycvDrr7+ia9eumDhxIho3boyffvoJvXr1wowZMzBo0KD3zm9iYgJNTU2kpKQotaekpMDCwqLAeSwtLVG7dm1oamoq2urVq4fk5GRkZ2cXOM/06dORnp6ueD148EDFLSUiIqLyROW7pS5cuICwsDBs3rwZGhoaGDp0KBYvXoy6desq+vTo0QMuLi7vXY6Ojg6cnZ0RFRWF7t27A3h7ZiYqKgr+/v4FztOsWTNs2rQJubm50NB4m8tu3boFS0tL6OjoFDiPVCqFVCpVdTOJiIionFL5zI2Liwtu376NVatWISkpCT/88INSsAGA6tWro3///h9cVkBAANauXYsNGzYgNjYWX375JbKysuDr6wsAGDp0KKZPn67o/+WXX+Lp06cYN24cbt26hX379mH+/PkYM2aMqptBREREIqXymZu7d+/CxsbmvX309fURFhb2wWX169cPT548wezZs5GcnIxGjRrh4MGDikHGiYmJijM0AGBtbY1Dhw5hwoQJaNiwIapUqYJx48Zh6tSpqm4GERERiZTK4SY1NRXJyclwdXVVaj9z5gw0NTXRuHFjlZbn7+9f6GWo6OjofG1ubm7466+/VFoHERER/XeofFlqzJgxBQ7KTUpK4uUhIiIiUjuVw82NGzfg5OSUr93R0RE3btwokaKIiIiIikvlcCOVSvPdvg0Ajx8/hpaWWj+qioiIiEj1cNOhQwfFs2PyPHv2DDNmzED79u1LtDgiIiIiVal8quWHH35Ay5YtYWNjA0dHRwDApUuXYG5ujo0bN5Z4gURERESqUDncVKlSBVeuXEFERAQuX74MXV1d+Pr6YsCAAdDW1v4UNRIREREVWbEGyejr62PkyJElXQsRERHRRyv2COAbN24gMTEx32c6de3a9aOLIiIiIiquYj2huEePHrh69SokEoni078lEgkAQC6Xl2yFRERERCpQ+W6pcePGoXr16khNTYWenh6uX7+O48ePo3HjxgU+UZiIiIioNKl85ub06dM4evQoTExMoKGhAQ0NDTRv3hzBwcEYO3YsLl68+CnqJCIiIioSlc/cyOVyGBoaAgBMTEzw6NEjAICNjQ3i4uJKtjoiIiIiFal85qZBgwa4fPkyqlevDldXVyxcuBA6OjpYs2YNatSo8SlqJCIiIioylcPNzJkzkZWVBQCYO3cuunTpghYtWqBy5cqIjIws8QKJiIiIVKFyuPHw8FD8v2bNmrh58yaePn2KihUrKu6YIiIiIlIXlcbc5OTkQEtLC9euXVNqr1SpEoMNERERlQkqhRttbW1Uq1aNz7IhIiKiMkvlu6W+/vprzJgxA0+fPv0U9RARERF9FJXH3Cxfvhx37tyBlZUVbGxsoK+vrzT9woULJVYcERERkapUDjfdu3f/BGUQERERlQyVw01gYOCnqIOIiIioRKg85oaIiIioLFP5zI2GhsZ7b/vmnVRERESkTiqHm507dyq9z8nJwcWLF7FhwwYEBQWVWGFERERExaFyuOnWrVu+tt69e+Ozzz5DZGQkhg8fXiKFERERERVHiY25+fzzzxEVFVVSiyMiIiIqlhIJNy9fvsTSpUtRpUqVklgcERERUbGpfFnq3x+QKQgCMjMzoaenh19++aVEiyMiIiJSlcrhZvHixUrhRkNDA6ampnB1dUXFihVLtDgiIiIiVakcbnx8fD5BGUREREQlQ+UxN2FhYdi6dWu+9q1bt2LDhg0lUhQRERFRcakcboKDg2FiYpKv3czMDPPnzy+RooiIiIiKS+Vwk5iYiOrVq+drt7GxQWJiYokURURERFRcKocbMzMzXLlyJV/75cuXUbly5RIpioiIiKi4VA43AwYMwNixY3Hs2DHI5XLI5XIcPXoU48aNQ//+/T9FjURERERFpvLdUvPmzUNCQgLatWsHLa23s+fm5mLo0KEcc0NERERqp3K40dHRQWRkJL755htcunQJurq6sLe3h42Nzaeoj4iIiEglKoebPLVq1UKtWrVKshYiIiKij6bymJtevXrhu+++y9e+cOFC9OnTp0SKIiIiIioulcPN8ePH0blz53ztnTp1wvHjx0ukKCIiIqLiUjncPH/+HDo6OvnatbW1kZGRUSJFERERERWXyuHG3t4ekZGR+dq3bNmC+vXrl0hRRERERMWl8oDiWbNmoWfPnoiPj0fbtm0BAFFRUdi0aRO2bdtW4gUSERERqULlcOPl5YVdu3Zh/vz52LZtG3R1deHg4ICjR4+iUqVKn6JGIiIioiIr1q3gnp6e8PT0BABkZGRg8+bNmDRpEs6fPw+5XF6iBRIRERGpQuUxN3mOHz8Ob29vWFlZISQkBG3btsVff/1VkrURERERqUylMzfJyckIDw/HunXrkJGRgb59++L169fYtWsXBxMTERFRmVDkMzdeXl6oU6cOrly5gtDQUDx69AjLli37lLURERERqazIZ24OHDiAsWPH4ssvv+THLhAREVGZVeQzNydOnEBmZiacnZ3h6uqK5cuXIy0t7VPWRkRERKSyIoebzz//HGvXrsXjx4/xxRdfYMuWLbCyskJubi4OHz6MzMzMT1knERERUZGofLeUvr4+hg0bhhMnTuDq1auYOHEiFixYADMzM3Tt2vVT1EhERERUZMW+FRwA6tSpg4ULF+Lhw4fYvHlzSdVEREREVGwfFW7yaGpqonv37tizZ09JLI6IiIio2Eok3BARERGVFQw3REREJCoMN0RERCQqDDdEREQkKgw3REREJCoMN0RERCQqZSLcrFixAra2tpDJZHB1dUVMTEyR5tuyZQskEgm6d+/+aQskIiKickPt4SYyMhIBAQEIDAzEhQsX4ODgAA8PD6Smpr53voSEBEyaNAktWrQopUqJiIioPFB7uFm0aBH8/Pzg6+uL+vXrY/Xq1dDT08P69esLnUcul2PQoEEICgpCjRo1SrFaIiIiKuvUGm6ys7Nx/vx5uLu7K9o0NDTg7u6O06dPFzrf3LlzYWZmhuHDh39wHa9fv0ZGRobSi4iIiMRLreEmLS0Ncrkc5ubmSu3m5uZITk4ucJ4TJ05g3bp1WLt2bZHWERwcDGNjY8XL2tr6o+smIiKiskvtl6VUkZmZiSFDhmDt2rUwMTEp0jzTp09Henq64vXgwYNPXCURERGpk5Y6V25iYgJNTU2kpKQotaekpMDCwiJf//j4eCQkJMDLy0vRlpubCwDQ0tJCXFwc7OzslOaRSqWQSqWfoHoiIiIqi9R65kZHRwfOzs6IiopStOXm5iIqKgpubm75+tetWxdXr17FpUuXFK+uXbuiTZs2uHTpEi85ERERkXrP3ABAQEAAvL290bhxYzRp0gShoaHIysqCr68vAGDo0KGoUqUKgoODIZPJ0KBBA6X5K1SoAAD52omIiOi/Se3hpl+/fnjy5Almz56N5ORkNGrUCAcPHlQMMk5MTISGRrkaGkRERERqpPZwAwD+/v7w9/cvcFp0dPR75w0PDy/5goiIiKjc4ikRIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhIVhhsiIiISFYYbIiIiEhWGGyIiIhKVMhFuVqxYAVtbW8hkMri6uiImJqbQvmvXrkWLFi1QsWJFVKxYEe7u7u/tT0RERP8tag83kZGRCAgIQGBgIC5cuAAHBwd4eHggNTW1wP7R0dEYMGAAjh07htOnT8Pa2hodOnRAUlJSKVdOREREZZHaw82iRYvg5+cHX19f1K9fH6tXr4aenh7Wr19fYP+IiAiMHj0ajRo1Qt26dfHTTz8hNzcXUVFRpVw5ERERlUVqDTfZ2dk4f/483N3dFW0aGhpwd3fH6dOni7SMFy9eICcnB5UqVSpw+uvXr5GRkaH0IiIiIvFSa7hJS0uDXC6Hubm5Uru5uTmSk5OLtIypU6fCyspKKSC9Kzg4GMbGxoqXtbX1R9dNREREZZfaL0t9jAULFmDLli3YuXMnZDJZgX2mT5+O9PR0xevBgwelXCURERGVJi11rtzExASamppISUlRak9JSYGFhcV75/3hhx+wYMECHDlyBA0bNiy0n1QqhVQqLZF6iYiIqOxT65kbHR0dODs7Kw0Gzhsc7ObmVuh8CxcuxLx583Dw4EE0bty4NEolIiKickKtZ24AICAgAN7e3mjcuDGaNGmC0NBQZGVlwdfXFwAwdOhQVKlSBcHBwQCA7777DrNnz8amTZtga2urGJtjYGAAAwMDtW0HERERlQ1qDzf9+vXDkydPMHv2bCQnJ6NRo0Y4ePCgYpBxYmIiNDT+d4Jp1apVyM7ORu/evZWWExgYiDlz5pRm6URERFQGqT3cAIC/vz/8/f0LnBYdHa30PiEh4dMXREREROVWub5bioiIiOjfGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVBhuiIiISFQYboiIiEhUGG6IiIhIVMpEuFmxYgVsbW0hk8ng6uqKmJiY9/bfunUr6tatC5lMBnt7e+zfv7+UKiUiIqKyTu3hJjIyEgEBAQgMDMSFCxfg4OAADw8PpKamFtj/1KlTGDBgAIYPH46LFy+ie/fu6N69O65du1bKlRMREVFZpPZws2jRIvj5+cHX1xf169fH6tWroaenh/Xr1xfYf8mSJejYsSMmT56MevXqYd68eXBycsLy5ctLuXIiIiIqi9QabrKzs3H+/Hm4u7sr2jQ0NODu7o7Tp08XOM/p06eV+gOAh4dHof2JiIjov0VLnStPS0uDXC6Hubm5Uru5uTlu3rxZ4DzJyckF9k9OTi6w/+vXr/H69WvF+/T0dABARkbGx5ReqNzXLz7JcosjQyKou4Sy5xN93cszHrNlHI/ZApWV45bHbCE+wXGb93tbED68z9UabkpDcHAwgoKC8rVbW1uroZrSZazuAsqiBdwrZRm/OgXgMVum8atTiE943GZmZsLY+P3LV2u4MTExgaamJlJSUpTaU1JSYGFhUeA8FhYWKvWfPn06AgICFO9zc3Px9OlTVK5cGRKJ5CO3oOzKyMiAtbU1Hjx4ACMjI3WXQ/RBPGapvOExW7oEQUBmZiasrKw+2Fet4UZHRwfOzs6IiopC9+7dAbwNH1FRUfD39y9wHjc3N0RFRWH8+PGKtsOHD8PNza3A/lKpFFKpVKmtQoUKJVF+uWBkZMRvOipXeMxSecNjtvR86IxNHrVflgoICIC3tzcaN26MJk2aIDQ0FFlZWfD19QUADB06FFWqVEFwcDAAYNy4cWjVqhVCQkLg6emJLVu24Ny5c1izZo06N4OIiIjKCLWHm379+uHJkyeYPXs2kpOT0ahRIxw8eFAxaDgxMREaGv+7qatp06bYtGkTZs6ciRkzZqBWrVrYtWsXGjRooK5NICIiojJEIhRl2DGVO69fv0ZwcDCmT5+e77IcUVnEY5bKGx6zZRfDDREREYmK2p9QTERERFSSGG6IiIhIVBhuiIiISFQYbojoo0gkEuzatUvdZZBI2draIjQ0tNjzh4eH/6eebaaKj923ZRnDTTnh4+MDiUSCUaNG5Zs2ZswYSCQS+Pj4KPrmPRSxILa2tpBIJJBIJNDX14eTkxO2bt36iSqnTy3v2JBIJNDW1kb16tUxZcoUvHr1St2lfVLvbve7rzt37qi1pvd974lNaWzv2bNnMXLkyCL1LeiXdb9+/XDr1q1irz88PFxxbGloaMDS0hL9+vVDYmJisZdZVqiyb8sbhptyxNraGlu2bMHLly8Vba9evcKmTZtQrVo1lZY1d+5cPH78GBcvXoSLiwv69euHU6dOlXTJVEo6duyIx48f4+7du1i8eDF+/PFHBAYGqrusTy5vu999Va9evVjLys7OLuHqqCSYmppCT0+v2PPr6urCzMzso2owMjLC48ePkZSUhO3btyMuLg59+vT5qGUWRU5Ozidd/sfu27KM4aYccXJygrW1NXbs2KFo27FjB6pVqwZHR0eVlmVoaAgLCwvUrl0bK1asgK6uLn777beSLplKiVQqhYWFBaytrdG9e3e4u7vj8OHDiul///03BgwYgCpVqkBPTw/29vbYvHmz0jJat26NsWPHYsqUKahUqRIsLCwwZ84cpT63b99Gy5YtIZPJUL9+faV15Ll69Sratm0LXV1dVK5cGSNHjsTz588V0/P+2p8/fz7Mzc1RoUIFzJ07F2/evMHkyZNRqVIlVK1aFWFhYUXe7ndfmpqaAIA//vgDTZo0gVQqhaWlJaZNm4Y3b94oba+/vz/Gjx8PExMTeHh4AACuXbuGTp06wcDAAObm5hgyZAjS0tIU823btg329vaK7XN3d0dWVhbmzJmDDRs2YPfu3Yq/9KOjoz+4DWL2oa9BZmYmBg0aBH19fVhaWmLx4sVo3bq10sfrvHs2RhAEzJkzB9WqVYNUKoWVlRXGjh0L4O3X8/79+5gwYYJi/wMFX5b67bff4OLiAplMBhMTE/To0eO92yGRSGBhYQFLS0s0bdoUw4cPR0xMjOJTqgFg9+7dcHJygkwmQ40aNRAUFKS0rTdv3kTz5s0V3ztHjhxRuqSbkJAAiUSCyMhItGrVCjKZDBEREQCAn376CfXq1YNMJkPdunWxcuVKxXKzs7Ph7+8PS0tLyGQy2NjYKJ7o/7799e99C7x9aG63bt1gYGAAIyMj9O3bV+mzHOfMmYNGjRph48aNsLW1hbGxMfr374/MzMz37j91YLgpZ4YNG6b0Q3/9+vWKj6ooLi0tLWhra/MvV5G4du0aTp06BR0dHUXbq1ev4OzsjH379uHatWsYOXIkhgwZgpiYGKV5N2zYAH19fZw5cwYLFy7E3LlzFQEmNzcXPXv2hI6ODs6cOYPVq1dj6tSpSvNnZWXBw8MDFStWxNmzZ7F161YcOXIk32fFHT16FI8ePcLx48exaNEiBAYGokuXLqhYsSLOnDmDUaNG4YsvvsDDhw+LtQ+SkpLQuXNnuLi44PLly1i1ahXWrVuHb775Jt/26ujo4OTJk1i9ejWePXuGtm3bwtHREefOncPBgweRkpKCvn37AgAeP36MAQMGYNiwYYiNjUV0dDR69uwJQRAwadIk9O3bV+lsUtOmTYtVvxgU5WsQEBCAkydPYs+ePTh8+DD+/PNPXLhwodBlbt++XXFm8vbt29i1axfs7e0BvP1Dr2rVqoqz0o8fPy5wGfv27UOPHj3QuXNnXLx4EVFRUWjSpEmRtys1NRU7d+6EpqamIkj/+eefGDp0KMaNG4cbN27gxx9/RHh4OL799lsAgFwuR/fu3aGnp4czZ85gzZo1+Prrrwtc/rRp0zBu3DjExsbCw8MDERERmD17Nr799lvExsZi/vz5mDVrFjZs2AAAWLp0Kfbs2YNff/0VcXFxiIiIgK2t7Qf317/l5uaiW7duePr0Kf744w8cPnwYd+/eRb9+/ZT6xcfHY9euXdi7dy/27t2LP/74AwsWLCjy/is1ApUL3t7eQrdu3YTU1FRBKpUKCQkJQkJCgiCTyYQnT54I3bp1E7y9vZX6FsbGxkZYvHixIAiC8Pr1a2H+/PkCAGHv3r2ffkOoxHl7ewuampqCvr6+IJVKBQCChoaGsG3btvfO5+npKUycOFHxvlWrVkLz5s2V+ri4uAhTp04VBEEQDh06JGhpaQlJSUmK6QcOHBAACDt37hQEQRDWrFkjVKxYUXj+/Lmiz759+wQNDQ0hOTlZUa+NjY0gl8sVferUqSO0aNFC8f7NmzeCvr6+sHnz5iJtd96rd+/egiAIwowZM4Q6deoIubm5iv4rVqwQDAwMFOtt1aqV4OjoqLTMefPmCR06dFBqe/DggQBAiIuLE86fPy8AEBISEgqt6X3fe2Lzvu390NcgIyND0NbWFrZu3aqY/uzZM0FPT08YN26cou3dn1chISFC7dq1hezs7ALX+W7fPGFhYYKxsbHivZubmzBo0KAib2NYWJgAQNDX1xf09PQEAAIAYezYsYo+7dq1E+bPn68038aNGwVLS0tBEN5+n2hpaQmPHz9WTD98+LDS9869e/cEAEJoaKjScuzs7IRNmzYptc2bN09wc3MTBEEQvvrqK6Ft27ZK+zmPKvvr999/FzQ1NYXExETF9OvXrwsAhJiYGEEQBCEwMFDQ09MTMjIyFH0mT54suLq6Frh8dVL7Z0uRakxNTeHp6Ynw8HAIggBPT0+YmJiovJypU6di5syZePXqFQwMDLBgwQJ4enp+goqpNLRp0warVq1CVlYWFi9eDC0tLfTq1UsxXS6XY/78+fj111+RlJSE7OxsvH79Ot/19oYNGyq9t7S0RGpqKgAgNjYW1tbWsLKyUkx3c3NT6h8bGwsHBwfo6+sr2po1a4bc3FzExcUpPjPus88+U/rMOHNzc6XPh9PU1ETlypUV6/7QdufJW29sbCzc3NwUlyby6nj+/DkePnyoGKPm7OystLzLly/j2LFjMDAwyLeu+Ph4dOjQAe3atYO9vT08PDzQoUMH9O7dGxUrVnxvnf9FH/oa/PPPP8jJyVE6a2JsbIw6deoUusw+ffogNDQUNWrUQMeOHdG5c2d4eXlBS6vov8ouXboEPz8/lbbF0NAQFy5cQE5ODg4cOICIiAjFWRng7XFz8uRJpTa5XI5Xr17hxYsXiIuLg7W1NSwsLBTTCztb1LhxY8X/s7KyEB8fj+HDhyvV/ObNG8WnY/v4+KB9+/aoU6cOOnbsiC5duqBDhw4AVNtfed/f1tbWirb69eujQoUKiI2NhYuLC4C3l7IMDQ0Vfd79GVGWMNyUQ8OGDVOc5l+xYkWxljF58mT4+PgoxhW8+wOIyh99fX3UrFkTwNtLlQ4ODli3bh2GDx8OAPj++++xZMkShIaGwt7eHvr6+hg/fny+S5Ha2tpK7yUSCXJzc0u83oLWU5x1v7vdxfFuCAOA58+fw8vLC999912+vpaWltDU1MThw4dx6tQp/P7771i2bBm+/vprnDlzptgDmanorK2tERcXhyNHjuDw4cMYPXo0vv/+e/zxxx/5jp/C6OrqqrxeDQ0NxXFWr149xMfH48svv8TGjRsBvD1ugoKC0LNnz3zzymQyldb17jGZN1Zt7dq1cHV1VeqXd0nMyckJ9+7dw4EDB3DkyBH07dsX7u7u2LZtW4nsr38rrZ8RH4tjbsqhjh07Ijs7Gzk5OYpBkKoyMTFBzZo1YWFhwWAjMhoaGpgxYwZmzpypuLPu5MmT6NatGwYPHgwHBwfUqFFD5dtj69WrhwcPHiiNZfjrr7/y9bl8+TKysrIUbSdPnoSGhsZ7/yIvafXq1cPp06chvPPReSdPnoShoSGqVq1a6HxOTk64fv06bG1tUbNmTaVX3i8diUSCZs2aISgoCBcvXoSOjg527twJANDR0YFcLv+0G1dOfOhrUKNGDWhra+Ps2bOK6enp6R88LnV1deHl5YWlS5ciOjoap0+fxtWrVwEUbf83bNgQUVFRH7Flb8fFREZGKsYHOTk5IS4uLt8xU7NmTcWx/+DBA6XBue9ud2HMzc1hZWWFu3fv5lvuu2HayMgI/fr1w9q1axEZGYnt27fj6dOnAN6/v96V9/394MEDRduNGzfw7Nkz1K9fv9j7Sl0YbsohTU1NxMbG4saNG4r0/m/p6em4dOmS0uvdg5bErU+fPtDU1FSc2atVq5bijENsbCy++OILpR+0ReHu7o7atWvD29sbly9fxp9//plvUOSgQYMgk8ng7e2Na9eu4dixY/jqq68wZMgQxSWp0jB69Gg8ePAAX331FW7evIndu3cjMDAQAQEBSpfD/m3MmDF4+vQpBgwYgLNnzyI+Ph6HDh2Cr68v5HI5zpw5g/nz5+PcuXNITEzEjh078OTJE9SrVw/A21P2V65cQVxcHNLS0j75rbxlQWE/az70NTA0NIS3tzcmT56MY8eO4fr16xg+fDg0NDQK/YMrPDwc69atw7Vr13D37l388ssv0NXVhY2NDYC3+//48eNISkpSusPtXYGBgdi8eTMCAwMRGxuLq1evFnim7n2sra3Ro0cPzJ49GwAwe/Zs/PzzzwgKCsL169cRGxuLLVu2YObMmQCA9u3bw87ODt7e3rhy5QpOnjypmPahPy6DgoIQHByMpUuX4tatW7h69SrCwsKwaNEiAMCiRYuwefNm3Lx5E7du3cLWrVthYWGBChUqfHB/vcvd3R329vYYNGgQLly4gJiYGAwdOhStWrVSulRWXjDclFNGRkYwMjIqdHp0dDQcHR2VXkFBQaVYIamTlpYW/P39sXDhQmRlZWHmzJlwcnKCh4cHWrduDQsLC5UfvqahoYGdO3fi5cuXaNKkCUaMGKE0xgAA9PT0cOjQITx9+hQuLi7o3bs32rVrh+XLl5fg1n1YlSpVsH//fsTExMDBwQGjRo3C8OHDFb9QCmNlZYWTJ09CLpejQ4cOsLe3x/jx41GhQgVoaGjAyMgIx48fR+fOnVG7dm3MnDkTISEh6NSpEwDAz88PderUQePGjWFqaoqTJ0+WxuaqVWE/a4ryNVi0aBHc3NzQpUsXuLu7o1mzZopbngtSoUIFrF27Fs2aNUPDhg1x5MgR/Pbbb6hcuTKAt8/vSkhIgJ2dHUxNTQtcRuvWrbF161bs2bMHjRo1Qtu2bfPdNVgUEyZMwL59+xATEwMPDw/s3bsXv//+O1xcXPD5559j8eLFihChqamJXbt24fnz53BxccGIESMUfxh86LLViBEj8NNPPyEsLAz29vZo1aoVwsPDFWduDA0NsXDhQjRu3BguLi5ISEjA/v37oaGh8cH99S6JRILdu3ejYsWKaNmyJdzd3VGjRg1ERkaqvG/KAonw7jlDIiIiNcnKykKVKlUQEhKiGC8mVidPnkTz5s1x584d2NnZqbsc0eGAYiIiUouLFy/i5s2baNKkCdLT0zF37lwAQLdu3dRcWcnbuXMnDAwMUKtWLdy5cwfjxo1Ds2bNGGw+EYYbIiJSmx9++AFxcXHQ0dGBs7Mz/vzzz2I93qKsy8zMxNSpU5GYmAgTExO4u7sjJCRE3WWJFi9LERERkahwQDERERGJCsMNERERiQrDDREREYkKww0RERGJCsMNEYledHQ0JBIJnj17VuR5bG1tERoa+slqIqJPh+GGiNTOx8cHEokEo0aNyjdtzJgxkEgk8PHxKf3CiKhcYrghojLB2toaW7ZsUXzYJwC8evUKmzZtQrVq1dRYGRGVNww3RFQmODk5wdraGjt27FC07dixA9WqVYOjo6Oi7fXr1xg7dizMzMwgk8nQvHnzfJ+wvH//ftSuXRu6urpo06YNEhIS8q3vxIkTaNGiBXR1dWFtbY2xY8cqfZo5EZVfDDdEVGYMGzYMYWFhivfr16+Hr6+vUp8pU6Zg+/bt2LBhAy5cuICaNWvCw8MDT58+BQA8ePAAPXv2hJeXFy5duoQRI0Zg2rRpSsuIj49Hx44d0atXL1y5cgWRkZE4ceIE/P39P/1GEtEnx3BDRGXG4MGDceLECdy/fx/379/HyZMnMXjwYMX0rKwsrFq1Ct9//z06deqE+vXrY+3atdDV1cW6desAAKtWrYKdnR1CQkJQp04dDBo0KN94neDgYAwaNAjjx49HrVq10LRpUyxduhQ///wzXr16VZqbTESfAD9biojKDFNTU3h6eiI8PByCIMDT01Ppc4bi4+ORk5ODZs2aKdq0tbXRpEkTxMbGAgBiY2Ph6uqqtFw3Nzel95cvX8aVK1cQERGhaBMEAbm5ubh37x7q1av3KTaPiEoJww0RlSnDhg1TXB5asWLFJ1nH8+fP8cUXX2Ds2LH5pnHwMlH5x3BDRGVKx44dkZ2dDYlEAg8PD6VpdnZ20NHRwcmTJ2FjYwMAyMnJwdmzZzF+/HgAQL169bBnzx6l+f766y+l905OTrhx4wZq1qz56TaEiNSGY26IqEzR1NREbGwsbty4AU1NTaVp+vr6+PLLLzF58mQcPHgQN27cgJ+fH168eIHhw4cDAEaNGoXbt29j8uTJiIuLw6ZNmxAeHq60nKlTp+LUqVPw9/fHpUuXcPv2bezevZsDiolEguGGiMocIyMjGBkZFThtwYIF6NWrF4YMGQInJyfcuXMHhw4dQsWKFQG8vay0fft27Nq1Cw4ODli9ejXmz5+vtIyGDRvijz/+wK1bt9CiRQs4Ojpi9uzZsLKy+uTbRkSfnkQQBEHdRRARERGVFJ65ISIiIlFhuCEiIiJRYbghIiIiUWG4ISIiIlFhuCEiIiJRYbghIiIiUWG4ISIiIlFhuCEiIiJRYbghIiIiUWG4ISIiIlFhuCEiIiJRYbghIiIiUfk/2Te8/ynLQJsAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml.classification import MultilayerPerceptronClassifier, RandomForestClassifier, LogisticRegression\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# class DataLoader:\n",
        "#     def __init__(self, file_path):\n",
        "#         self.spark = SparkSession.builder.appName(\"MNISTClassifier\").getOrCreate()\n",
        "#         self.data = self.spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "#     def preprocess(self):\n",
        "#         feature_columns = self.data.columns[:-1]\n",
        "#         label_column = self.data.columns[-1]  # Giả sử cột nhãn là cột cuối cùng\n",
        "#         assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "#         self.data = assembler.transform(self.data).withColumnRenamed(label_column, \"label\").select(\"features\", \"label\")\n",
        "#         self.train_data, self.test_data = self.data.randomSplit([0.8, 0.2], seed=1234)\n",
        "#         return self.train_data, self.test_data\n",
        "\n",
        "# class Classifier:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "#         self.evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "\n",
        "#     def train(self, train_data):\n",
        "#         self.model = self.model.fit(train_data)\n",
        "\n",
        "#     def evaluate(self, data):\n",
        "#         predictions = self.model.transform(data)\n",
        "#         accuracy = self.evaluator.evaluate(predictions)\n",
        "#         return accuracy\n",
        "\n",
        "# class MultiLayerPerceptron(Classifier):\n",
        "#     def __init__(self):\n",
        "#         layers = [784, 128, 64, 10]  # Cấu trúc mạng MLP\n",
        "#         mlp = MultilayerPerceptronClassifier(layers=layers, seed=1234)\n",
        "#         super().__init__(mlp)\n",
        "\n",
        "# class RandomForest(Classifier):\n",
        "#     def __init__(self):\n",
        "#         rf = RandomForestClassifier(numTrees=100, seed=1234)\n",
        "#         super().__init__(rf)\n",
        "\n",
        "# class LogisticRegressionModel(Classifier):\n",
        "#     def __init__(self):\n",
        "#         lr = LogisticRegression(maxIter=100, regParam=0.3, elasticNetParam=0.8)\n",
        "#         super().__init__(lr)\n",
        "\n",
        "# def plot_accuracies(train_accuracies, test_accuracies, labels):\n",
        "#     x = range(len(labels))\n",
        "#     fig, ax = plt.subplots()\n",
        "#     ax.bar(x, train_accuracies, width=0.4, label='Train Accuracy', align='center')\n",
        "#     ax.bar(x, test_accuracies, width=0.4, label='Test Accuracy', align='edge')\n",
        "#     ax.set_xlabel('Model')\n",
        "#     ax.set_ylabel('Accuracy')\n",
        "#     ax.set_title('Comparison of Model Accuracies')\n",
        "#     ax.set_xticks(x)\n",
        "#     ax.set_xticklabels(labels)\n",
        "#     ax.legend()\n",
        "#     plt.show()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     data_loader = DataLoader(\"/content/drive/MyDrive/Colab_Notebooks/mnist_mini.csv\")\n",
        "#     train_data, test_data = data_loader.preprocess()\n",
        "\n",
        "#     classifiers = [MultiLayerPerceptron(), RandomForest(), LogisticRegressionModel()]\n",
        "#     labels = [\"MLP\", \"Random Forest\", \"Logistic Regression\"]\n",
        "\n",
        "#     train_accuracies = []\n",
        "#     test_accuracies = []\n",
        "\n",
        "#     for classifier in classifiers:\n",
        "#         classifier.train(train_data)\n",
        "#         train_accuracy = classifier.evaluate(train_data)\n",
        "#         test_accuracy = classifier.evaluate(test_data)\n",
        "#         train_accuracies.append(train_accuracy)\n",
        "#         test_accuracies.append(test_accuracy)\n",
        "\n",
        "#     plot_accuracies(train_accuracies, test_accuracies, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDdXsa-2iVhW"
      },
      "outputs": [],
      "source": [
        "# class SparkClassifier:\n",
        "#   def __init__(self, model, label_col=\"label\", features_col = \"features\"):\n",
        "#     self.model = model\n",
        "#     self.label_col = label_col\n",
        "#     self.features_col = features_col\n",
        "\n",
        "#   def train(self, train_data):\n",
        "#     if isinstance(self.model, LinearSVC):\n",
        "#       ovr = OneVsRest(classifier=self.model, labelCol=self.label_col,\n",
        "#                       featuresCol=self.features_col)\n",
        "#       return ovr.fit(train_data)\n",
        "#     else:\n",
        "#       return self.model.fit(train_data)\n",
        "\n",
        "#   def evaluate(self, model, test_data):\n",
        "#     predictions = model.transform(test_data)\n",
        "#     evaluator = MulticlassClassificationEvaluator(labelCol=self.label_col,\n",
        "#                                                   predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "#     accuracy = evaluator.evaluate(predictions)\n",
        "#     return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7LP5Vbtfopd3"
      },
      "outputs": [],
      "source": [
        "# class SparkMLPClassifier(SparkClassifier):\n",
        "#   def __init__(self, layers):\n",
        "#     model=MultilayerPerceptronClassifier(layers=layers)\n",
        "#     super().__init__(model)\n",
        "# class SparkRandomForestClassifier(SparkClassifier):\n",
        "#   def __init__(self):\n",
        "#     model = RandomForestClassifier()\n",
        "#     super().__init__(model)\n",
        "\n",
        "# class SparkLinearSVMClassifier(SparkClassifier):\n",
        "#   def __init__(self):\n",
        "#     model = LinearSVC(labelCol=\"label\", maxIter=50)\n",
        "#     super().__init(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j49XBBhlqw71"
      },
      "outputs": [],
      "source": [
        "# class SparkClassificationWorkFlow:\n",
        "#   def __init__(self):\n",
        "#     self.model_names = [\"MLP\", \"Random Forest\", \"Linear SVM\"]\n",
        "#     self.train_accuracies = {\"original\": [], \"svd\": []}\n",
        "#     self.test_accuracies = {\"original\": [], \"svd\": []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9nferCeTrdut"
      },
      "outputs": [],
      "source": [
        "# from pyspark.sql import SQLContext\n",
        "# from pyspark.ml.linalg import Vectors\n",
        "# from pyspark.sql import functions as f\n",
        "\n",
        "# def load_data(self, input_path):\n",
        "#     data = sqlc.read.csv(input_path, sep=',', inferSchema=True, header=False)\n",
        "#     data = data.rdd.map(lambda x: (x[0], Vectors.dense([float(it) for it in x[1:]]))) \\\n",
        "#                   .toDF() \\\n",
        "#                   .select(f.col('_1').alias('label'), f.col('_2').alias('features'))\n",
        "#     return data\n",
        "\n",
        "# def train_and_evaluate(self, classifier, train_data, test_data):\n",
        "#     model = classifier.train(train_data)\n",
        "#     train_accuracy = classifier.evaluate(model, train_data)\n",
        "#     test_accuracy = classifier.evaluate(model, test_data)\n",
        "#     return train_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Er421WAKttZZ"
      },
      "outputs": [],
      "source": [
        "# def run_workflow(self, train_data, test_data, train_data_svd, test_data_svd):\n",
        "#   classifiers = [SparkMLPClassifier(layers=None),\n",
        "#                  SparkRandomForestClassifier(), SparkLinearSVMClassifier()]\n",
        "#   for classifier in classifiers:\n",
        "#     for data_type, (train, test) in zip([\"original\", \"svd\"],\n",
        "#                                         [(train_data, test_data), (train_data_svd, test_data_svd)]):\n",
        "#       # For MLP classifier, update the layers based on the number of features\n",
        "#       if isinstance(classifier, SparkMLPClassifier):\n",
        "#         num_input_features = len(train.select(\"features\").first()[0])\n",
        "#         layers = [num_input_features, 128, (train.agg({\"label\": \"max\"}).first()[0] + 1)]\n",
        "#         classifier.model.setLayers(layers)\n",
        "#       else:\n",
        "#         layers = None # For non-MLP classifiers, layers can be None\n",
        "#       if layers is not None:\n",
        "#         classifier_instance = type(classifier)(layers=layers)\n",
        "#       else:\n",
        "#         classifier_instance = type(classifier)()\n",
        "\n",
        "#       train_acc, test_acc = self.train_and_evaluate(classifier_instance, train, test)\n",
        "#       self.train_accuracies[data_type].append(train_acc)\n",
        "#       self.test_accuracies[data_type].append(test_acc)\n",
        "#   self.display_accuracies()\n",
        "#   self.plot_quad_bar_chart()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vfdIjMX9zUH3"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# def display_accuracies(self):\n",
        "#   for data_type in [\"original\", \"svd\"]:\n",
        "#     for i in range(len(self.model_names)):\n",
        "#       print(f\"\"\"{data_type.capitalize()} {self.model_names[i]}\n",
        "#             Train Accuracy: {self.train_accuracies[data_type][i]}\"\"\")\n",
        "#       print(f\"\"\"{data_type.capitalize()} {self.model_names[i]}\n",
        "#             Test Accuracy: {self.test_accuracies[data_type][i]}\"\"\")\n",
        "#       print()\n",
        "\n",
        "# def plot_quad_bar_chart(self):\n",
        "#   bar_width = 0.2\n",
        "#   bar_train_original = np.arange(len(self.model_names))\n",
        "#   bar_train_svd = bar_train_original + bar_width\n",
        "#   bar_test_original = bar_train_svd + bar_width\n",
        "#   bar_test_svd = bar_test_original + bar_width\n",
        "\n",
        "#   plt.bar(bar_train_original, self.train_accuracies[\"original\"], width=bar_width, label='Train (Original)')\n",
        "#   plt.bar(bar_train_svd, self.train_accuracies[\"svd\"], width=bar_width, label='Train (SVD)')\n",
        "#   plt.bar(bar_test_original, self.test_accuracies[\"original\"], width=bar_width, label='Test (Original)')\n",
        "#   plt.bar(bar_test_svd, self.test_accuracies[\"svd\"], width=bar_width, label='Test (SVD)')\n",
        "\n",
        "#   plt.xlabel('Models')\n",
        "#   plt.ylabel('Accuracy')\n",
        "#   plt.title('Model Accuracies in Training and Test Sets')\n",
        "#   plt.xticks(bar_train_original + bar_width, self.model_names)\n",
        "#   plt.legend()\n",
        "\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "H6js2UOs3_4J",
        "outputId": "524efc46-aed6-4f7f-b03e-52454a681f1c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml.classification import MultilayerPerceptronClassifier, RandomForestClassifier, LinearSVC, OneVsRest\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Data Loader Class\n",
        "# class DataLoader:\n",
        "#     def __init__(self, file_path):\n",
        "#         self.spark = SparkSession.builder.appName(\"MNISTClassifier\").getOrCreate()\n",
        "#         self.data = self.spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "#     def preprocess(self):\n",
        "#         feature_columns = self.data.columns[:-1]\n",
        "#         label_column = self.data.columns[-1]\n",
        "#         assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "#         self.data = assembler.transform(self.data).withColumnRenamed(label_column, \"label\").select(\"features\", \"label\")\n",
        "#         self.train_data, self.test_data = self.data.randomSplit([0.8, 0.2], seed=1234)\n",
        "#         return self.train_data, self.test_data\n",
        "\n",
        "# # Base Classifier Class\n",
        "# class Classifier:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "#         self.evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "\n",
        "#     def train(self, train_data):\n",
        "#         self.model = self.model.fit(train_data)\n",
        "\n",
        "#     def evaluate(self, data):\n",
        "#         predictions = self.model.transform(data)\n",
        "#         accuracy = self.evaluator.evaluate(predictions)\n",
        "#         return accuracy\n",
        "\n",
        "# # Multi-layer Perceptron Classifier\n",
        "# class MultiLayerPerceptron(Classifier):\n",
        "#     def __init__(self):\n",
        "#         layers = [784, 128, 64, 10]\n",
        "#         mlp = MultilayerPerceptronClassifier(layers=layers, seed=1234)\n",
        "#         super().__init__(mlp)\n",
        "\n",
        "# # Random Forest Classifier\n",
        "# class RandomForest(Classifier):\n",
        "#     def __init__(self):\n",
        "#         rf = RandomForestClassifier(numTrees=100, seed=1234)\n",
        "#         super().__init__(rf)\n",
        "\n",
        "# # Linear SVM Classifier (handled via OneVsRest)\n",
        "# class LinearSVM(Classifier):\n",
        "#     def __init__(self):\n",
        "#         lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
        "#         ovr = OneVsRest(classifier=lsvc)\n",
        "#         super().__init__(ovr)\n",
        "\n",
        "# # Workflow to train, evaluate, and plot results\n",
        "# class SparkClassificationWorkflow:\n",
        "#     def __init__(self):\n",
        "#         self.model_names = [\"MLP\", \"Random Forest\", \"Linear SVM\"]\n",
        "#         self.train_accuracies = []\n",
        "#         self.test_accuracies = []\n",
        "\n",
        "#     def load_data(self, input_path):\n",
        "#         data_loader = DataLoader(input_path)\n",
        "#         return data_loader.preprocess()\n",
        "\n",
        "#     def train_and_evaluate(self, classifier, train_data, test_data):\n",
        "#         classifier.train(train_data)\n",
        "#         train_accuracy = classifier.evaluate(train_data)\n",
        "#         test_accuracy = classifier.evaluate(test_data)\n",
        "#         return train_accuracy, test_accuracy\n",
        "\n",
        "#     def run_workflow(self, train_data, test_data):\n",
        "#         classifiers = [MultiLayerPerceptron(), RandomForest(), LinearSVM()]\n",
        "#         for classifier in classifiers:\n",
        "#             train_acc, test_acc = self.train_and_evaluate(classifier, train_data, test_data)\n",
        "#             self.train_accuracies.append(train_acc)\n",
        "#             self.test_accuracies.append(test_acc)\n",
        "#         self.plot_accuracies()\n",
        "\n",
        "#     def plot_accuracies(self):\n",
        "#         x = np.arange(len(self.model_names))\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.bar(x - 0.2, self.train_accuracies, width=0.4, label='Train Accuracy')\n",
        "#         ax.bar(x + 0.2, self.test_accuracies, width=0.4, label='Test Accuracy')\n",
        "#         ax.set_xlabel('Model')\n",
        "#         ax.set_ylabel('Accuracy')\n",
        "#         ax.set_title('Comparison of Model Accuracies')\n",
        "#         ax.set_xticks(x)\n",
        "#         ax.set_xticklabels(self.model_names)\n",
        "#         ax.legend()\n",
        "#         plt.show()\n",
        "\n",
        "# # Main Execution\n",
        "# if __name__ == \"__main__\":\n",
        "#     workflow = SparkClassificationWorkflow()\n",
        "#     train_data, test_data = workflow.load_data(\"/content/drive/MyDrive/Colab_Notebooks/mnist_mini.csv\")\n",
        "#     workflow.run_workflow(train_data, test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BKuMFviK7I-y",
        "outputId": "090042e9-04e1-4c2a-af4d-72aa4336f3f4"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o75.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 61.0 failed 1 times, most recent failure: Lost task 4.0 in stage 61.0 (TID 283) (192.168.1.5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m workflow \u001b[38;5;241m=\u001b[39m SparkClassificationWorkflow()\n\u001b[0;32m     98\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mload_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_mini.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[3], line 77\u001b[0m, in \u001b[0;36mSparkClassificationWorkflow.run_workflow\u001b[1;34m(self, train_data, test_data)\u001b[0m\n\u001b[0;32m     75\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m [MultiLayerPerceptron(), RandomForest(), LinearSVM()]\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[1;32m---> 77\u001b[0m     train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_accuracies\u001b[38;5;241m.\u001b[39mappend(test_acc)\n",
            "Cell \u001b[1;32mIn[3], line 70\u001b[0m, in \u001b[0;36mSparkClassificationWorkflow.train_and_evaluate\u001b[1;34m(self, classifier, train_data, test_data)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, classifier, train_data, test_data):\n\u001b[0;32m     69\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mtrain(train_data)\n\u001b[1;32m---> 70\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_accuracy, test_accuracy\n",
            "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mClassifier.evaluate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m     33\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m---> 34\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\ml\\evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\ml\\evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o75.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 61.0 failed 1 times, most recent failure: Lost task 4.0 in stage 61.0 (TID 283) (192.168.1.5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n"
          ]
        }
      ],
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml.classification import MultilayerPerceptronClassifier, RandomForestClassifier, LinearSVC, OneVsRest\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Data Loader Class\n",
        "# class DataLoader:\n",
        "#     def __init__(self, file_path):\n",
        "#         self.spark = SparkSession.builder.appName(\"MNISTClassifier\").getOrCreate()\n",
        "#         self.data = self.spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "#     def preprocess(self):\n",
        "#         # Assuming the last column is the label\n",
        "#         feature_columns = self.data.columns[:-1]\n",
        "#         label_column = self.data.columns[-1]\n",
        "#         assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "#         self.data = assembler.transform(self.data).withColumnRenamed(label_column, \"label\").select(\"features\", \"label\")\n",
        "#         self.train_data, self.test_data = self.data.randomSplit([0.8, 0.2], seed=1234)\n",
        "#         return self.train_data, self.test_data\n",
        "\n",
        "# # Base Classifier Class\n",
        "# class Classifier:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model\n",
        "#         self.evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "\n",
        "#     def train(self, train_data):\n",
        "#         self.model = self.model.fit(train_data)\n",
        "\n",
        "#     def evaluate(self, data):\n",
        "#         predictions = self.model.transform(data)\n",
        "#         accuracy = self.evaluator.evaluate(predictions)\n",
        "#         return accuracy\n",
        "\n",
        "# # Multi-layer Perceptron Classifier\n",
        "# class MultiLayerPerceptron(Classifier):\n",
        "#     def __init__(self):\n",
        "#         layers = [784, 128, 64, 10]\n",
        "#         mlp = MultilayerPerceptronClassifier(layers=layers, seed=1234)\n",
        "#         super().__init__(mlp)\n",
        "\n",
        "# # Random Forest Classifier\n",
        "# class RandomForest(Classifier):\n",
        "#     def __init__(self):\n",
        "#         rf = RandomForestClassifier(numTrees=100, seed=1234)\n",
        "#         super().__init__(rf)\n",
        "\n",
        "# # Linear SVM Classifier (handled via OneVsRest)\n",
        "# class LinearSVM(Classifier):\n",
        "#     def __init__(self):\n",
        "#         lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
        "#         ovr = OneVsRest(classifier=lsvc)\n",
        "#         super().__init__(ovr)\n",
        "\n",
        "# # Workflow to train, evaluate, and plot results\n",
        "# class SparkClassificationWorkflow:\n",
        "#     def __init__(self):\n",
        "#         self.model_names = [\"MLP\", \"Random Forest\", \"Linear SVM\"]\n",
        "#         self.train_accuracies = []\n",
        "#         self.test_accuracies = []\n",
        "\n",
        "#     def load_data(self, input_path):\n",
        "#         data_loader = DataLoader(input_path)\n",
        "#         return data_loader.preprocess()\n",
        "\n",
        "#     def train_and_evaluate(self, classifier, train_data, test_data):\n",
        "#         classifier.train(train_data)\n",
        "#         train_accuracy = classifier.evaluate(train_data)\n",
        "#         test_accuracy = classifier.evaluate(test_data)\n",
        "#         return train_accuracy, test_accuracy\n",
        "\n",
        "#     def run_workflow(self, train_data, test_data):\n",
        "#         classifiers = [MultiLayerPerceptron(), RandomForest(), LinearSVM()]\n",
        "#         for classifier in classifiers:\n",
        "#             train_acc, test_acc = self.train_and_evaluate(classifier, train_data, test_data)\n",
        "#             self.train_accuracies.append(train_acc)\n",
        "#             self.test_accuracies.append(test_acc)\n",
        "#         self.plot_accuracies()\n",
        "\n",
        "#     def plot_accuracies(self):\n",
        "#         x = np.arange(len(self.model_names))\n",
        "#         fig, ax = plt.subplots()\n",
        "#         ax.bar(x - 0.2, self.train_accuracies, width=0.4, label='Train Accuracy')\n",
        "#         ax.bar(x + 0.2, self.test_accuracies, width=0.4, label='Test Accuracy')\n",
        "#         ax.set_xlabel('Model')\n",
        "#         ax.set_ylabel('Accuracy')\n",
        "#         ax.set_title('Comparison of Model Accuracies')\n",
        "#         ax.set_xticks(x)\n",
        "#         ax.set_xticklabels(self.model_names)\n",
        "#         ax.legend()\n",
        "#         plt.show()\n",
        "\n",
        "# # Main Execution\n",
        "# if __name__ == \"__main__\":\n",
        "#     workflow = SparkClassificationWorkflow()\n",
        "#     train_data, test_data = workflow.load_data(\"mnist_mini.csv\")\n",
        "#     workflow.run_workflow(train_data, test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o833.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 124.0 failed 1 times, most recent failure: Lost task 2.0 in stage 124.0 (TID 565) (192.168.1.5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m workflow \u001b[38;5;241m=\u001b[39m SparkClassificationWorkflow()\n\u001b[0;32m    108\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mload_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_mini.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[5], line 87\u001b[0m, in \u001b[0;36mSparkClassificationWorkflow.run_workflow\u001b[1;34m(self, train_data, test_data)\u001b[0m\n\u001b[0;32m     85\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m [MultiLayerPerceptron(), RandomForest(), LinearSVM()]\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classifier \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[1;32m---> 87\u001b[0m     train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_accuracies\u001b[38;5;241m.\u001b[39mappend(test_acc)\n",
            "Cell \u001b[1;32mIn[5], line 80\u001b[0m, in \u001b[0;36mSparkClassificationWorkflow.train_and_evaluate\u001b[1;34m(self, classifier, train_data, test_data)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, classifier, train_data, test_data):\n\u001b[0;32m     79\u001b[0m     classifier\u001b[38;5;241m.\u001b[39mtrain(train_data)\n\u001b[1;32m---> 80\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_accuracy, test_accuracy\n",
            "Cell \u001b[1;32mIn[5], line 44\u001b[0m, in \u001b[0;36mClassifier.evaluate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m     43\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m---> 44\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\ml\\evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\ml\\evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o833.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 124.0 failed 1 times, most recent failure: Lost task 2.0 in stage 124.0 (TID 565) (192.168.1.5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:738)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\r\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:737)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions$lzycompute(MulticlassMetrics.scala:61)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.confusions(MulticlassMetrics.scala:52)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass$lzycompute(MulticlassMetrics.scala:78)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.tpByClass(MulticlassMetrics.scala:76)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy$lzycompute(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.mllib.evaluation.MulticlassMetrics.accuracy(MulticlassMetrics.scala:188)\r\n\tat org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator.evaluate(MulticlassClassificationEvaluator.scala:153)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)\r\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:695)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:660)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:636)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:582)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:541)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 49 more\r\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier, RandomForestClassifier, LinearSVC, OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data Loader Class\n",
        "class DataLoader:\n",
        "    def __init__(self, file_path):\n",
        "        conf = SparkConf() \\\n",
        "            .setAppName(\"MNISTClassifier\") \\\n",
        "            .set(\"spark.python.worker.reuse\", \"true\") \\\n",
        "            .set(\"spark.worker.timeout\", \"600\") \\\n",
        "            .set(\"spark.network.timeout\", \"600s\") \\\n",
        "            .set(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
        "            .set(\"spark.executor.memory\", \"2g\") \\\n",
        "            .set(\"spark.executor.cores\", \"2\") \\\n",
        "            .set(\"spark.driver.memory\", \"2g\")\n",
        "\n",
        "        self.spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "        self.data = self.spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "    def preprocess(self):\n",
        "        feature_columns = self.data.columns[:-1]\n",
        "        label_column = self.data.columns[-1]\n",
        "        assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "        self.data = assembler.transform(self.data).withColumnRenamed(label_column, \"label\").select(\"features\", \"label\")\n",
        "        self.train_data, self.test_data = self.data.randomSplit([0.8, 0.2], seed=1234)\n",
        "        return self.train_data, self.test_data\n",
        "\n",
        "# Base Classifier Class\n",
        "class Classifier:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "\n",
        "    def train(self, train_data):\n",
        "        self.model = self.model.fit(train_data)\n",
        "\n",
        "    def evaluate(self, data):\n",
        "        predictions = self.model.transform(data)\n",
        "        accuracy = self.evaluator.evaluate(predictions)\n",
        "        return accuracy\n",
        "\n",
        "# Multi-layer Perceptron Classifier\n",
        "class MultiLayerPerceptron(Classifier):\n",
        "    def __init__(self):\n",
        "        layers = [784, 128, 64, 10]\n",
        "        mlp = MultilayerPerceptronClassifier(layers=layers, seed=1234)\n",
        "        super().__init__(mlp)\n",
        "\n",
        "# Random Forest Classifier\n",
        "class RandomForest(Classifier):\n",
        "    def __init__(self):\n",
        "        rf = RandomForestClassifier(numTrees=100, seed=1234)\n",
        "        super().__init__(rf)\n",
        "\n",
        "# Linear SVM Classifier (handled via OneVsRest)\n",
        "class LinearSVM(Classifier):\n",
        "    def __init__(self):\n",
        "        lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
        "        ovr = OneVsRest(classifier=lsvc)\n",
        "        super().__init__(ovr)\n",
        "\n",
        "# Workflow to train, evaluate, and plot results\n",
        "class SparkClassificationWorkflow:\n",
        "    def __init__(self):\n",
        "        self.model_names = [\"MLP\", \"Random Forest\", \"Linear SVM\"]\n",
        "        self.train_accuracies = []\n",
        "        self.test_accuracies = []\n",
        "\n",
        "    def load_data(self, input_path):\n",
        "        data_loader = DataLoader(input_path)\n",
        "        return data_loader.preprocess()\n",
        "\n",
        "    def train_and_evaluate(self, classifier, train_data, test_data):\n",
        "        classifier.train(train_data)\n",
        "        train_accuracy = classifier.evaluate(train_data)\n",
        "        test_accuracy = classifier.evaluate(test_data)\n",
        "        return train_accuracy, test_accuracy\n",
        "\n",
        "    def run_workflow(self, train_data, test_data):\n",
        "        classifiers = [MultiLayerPerceptron(), RandomForest(), LinearSVM()]\n",
        "        for classifier in classifiers:\n",
        "            train_acc, test_acc = self.train_and_evaluate(classifier, train_data, test_data)\n",
        "            self.train_accuracies.append(train_acc)\n",
        "            self.test_accuracies.append(test_acc)\n",
        "        self.plot_accuracies()\n",
        "\n",
        "    def plot_accuracies(self):\n",
        "        x = np.arange(len(self.model_names))\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.bar(x - 0.2, self.train_accuracies, width=0.4, label='Train Accuracy')\n",
        "        ax.bar(x + 0.2, self.test_accuracies, width=0.4, label='Test Accuracy')\n",
        "        ax.set_xlabel('Model')\n",
        "        ax.set_ylabel('Accuracy')\n",
        "        ax.set_title('Comparison of Model Accuracies')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(self.model_names)\n",
        "        ax.legend()\n",
        "        plt.show()\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    workflow = SparkClassificationWorkflow()\n",
        "    train_data, test_data = workflow.load_data(\"mnist_mini.csv\")\n",
        "    workflow.run_workflow(train_data, test_data)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
